---
title: "Comparative Analysis of Random Forest and MLR for NMR"
author: "Sandeep Thullimalli"
date: "2025-03-10"
output: html_document
---

# 1. Introduction

Neonatal mortality rate (NMR) is an important indicator of child health. This document compares "Multiple Linear Regression (MLR)" and "Random Forest (RF)" models for predicting NMR using NFHS data.This document describes the data preparation and cleaning process for the **NFHS-5 Factsheets Data**. The original dataset, `NFHS_5_Factsheets_Data_5`, was cleaned and transformed into `nfhs5` for further analysis.

------------------------------------------------------------------------

## 1. install required packages

```{r setup-packages, eval=FALSE}
# install these packages before knitting:code is given below:

install.packages(c(
  "dplyr", "readr", "randomForest", "caret",
  "summarytools", "tidyverse", "corrplot", 
  "ggplot2", "DataExplorer", "naniar"
))


```

## 2. Load the required packages
```{r}
library(dplyr)
library(readr)
library(randomForest)
library(caret)
library(summarytools)
library(tidyverse)
library(corrplot)
library(ggplot2)
library(DataExplorer)
library(naniar)

```


## 3. Read the original dataset that is saved in RDS format

```{r message=FALSE, warning=FALSE}
# change the name for easier typing

nfhs5 <- readRDS("NFHS5_cleaned.rds")

# Check the first few rows

head(nfhs5)
sapply(nfhs5, class)
unique(nfhs5$StatesUTs)


# Exploratory data analysis


# Check first few rows
head(nfhs5)

# Structure of the dataset
str(nfhs5)

# Summary statistics
summary(nfhs5)

# Count missing values per column
colSums(is.na(nfhs5))

# Visualize missing values
plot_missing(nfhs5)

#Check the proportion of missing values

missing_pct <- colSums(is.na(nfhs5)) / nrow(nfhs5) * 100
print(missing_pct[missing_pct > 0]) # Show only columns with missing data

### **Missing Data Analysis and Handling**

#### **1. Visualizing Missing Data**
install.packages('naniar')
library(naniar)
gg_miss_var(nfhs5) # Show missing data per variable
vis_miss(nfhs5)    # Heatmap of missing values

#Moderate Missingness (5-20%) → Can be imputed with mean/median
#### **2. Handling Missing Data**
##### **Numerical Variables (Impute with Median)**

#Convert column names to valid syntax; "Under-5.mortality.rate to Under.5.mortality.rate
colnames(nfhs5) <- make.names(colnames(nfhs5), unique = TRUE)


nfhs5 <- nfhs5 %>%
  mutate(
    Neonatal.mortality.rate.per.1000.live.births = ifelse(
      is.na(Neonatal.mortality.rate.per.1000.live.births), 
      median(Neonatal.mortality.rate.per.1000.live.births, na.rm = TRUE),
      Neonatal.mortality.rate.per.1000.live.births),
    
    Infant.mortality.rate.per.1000.live.births = ifelse(
      is.na(Infant.mortality.rate.per.1000.live.births), 
      median(Infant.mortality.rate.per.1000.live.births, na.rm = TRUE),
      Infant.mortality.rate.per.1000.live.births),
    
    Under.five.mortality.rate.per.1000.live.births = ifelse(
      is.na(Under.five.mortality.rate.per.1000.live.births), 
      median(Under.five.mortality.rate.per.1000.live.births, na.rm = TRUE),
      Under.five.mortality.rate.per.1000.live.births)
  )

#Categorical Variables (Replace NA with 'Unknown')

nfhs5 <- nfhs5 %>%
  mutate(
    Children.born.at.home.who.were.taken.to.a.health.facility.for.a.check.up.within.24.hours.of.birth.for.last.birth.in.the.5.years.before.the.survey.Pct = 
      ifelse(is.na(Children.born.at.home.who.were.taken.to.a.health.facility.for.a.check.up.within.24.hours.of.birth.for.last.birth.in.the.5.years.before.the.survey.Pct), 
             "Unknown",
             Children.born.at.home.who.were.taken.to.a.health.facility.for.a.check.up.within.24.hours.of.birth.for.last.birth.in.the.5.years.before.the.survey.Pct)
  )
# **Drop Variables with High Missingness (>40%)
nfhs5 <- nfhs5 %>% select(-Children.born.at.home.who.were.taken.to.a.health.facility.for.a.check.up.within.24.hours.of.birth.for.last.birth.in.the.5.years.before.the.survey.Pct)

## **Exploratory Data Analysis (EDA)**

#### **1. Summary Statistics**

summary(nfhs5)

# view correlation table for neonatal mortality rate, as it is difficult to look view plot due to long variable names

# Calculate correlation of Neonatal Mortality Rate with all other numeric variables
cor_nmr <- cor(nfhs5 %>% select(where(is.numeric)), use = "complete.obs")

# Extract the correlations of NMR
nmr_corr <- cor_nmr["Neonatal.mortality.rate.per.1000.live.births", ]

# Convert to dataframe and sort by absolute correlation
nmr_corr_df <- data.frame(Variable = names(nmr_corr), Correlation = nmr_corr) %>%
  arrange(desc(abs(Correlation)))

# View top correlated variables (excluding NMR itself)
print(nmr_corr_df[-1, ])  # Exclude first row as it is correlation with itself

#Drop IMR and U5MR from the dataset, as they are highly correlated



nfhs5 <- nfhs5 %>% select(-Infant.mortality.rate.per.1000.live.births, -Under.five.mortality.rate.per.1000.live.births )

# check for correlation again
# Compute correlation of all numerical variables with NMR
cor_matrix <- cor(nfhs5 %>% select_if(is.numeric), use = "complete.obs")

# Extract correlation values with Neonatal Mortality Rate
cor_nmr <- cor_matrix["Neonatal.mortality.rate.per.1000.live.births", ]

# Sort correlations in descending order (absolute value for strength)
cor_nmr_sorted <- sort(cor_nmr, decreasing = TRUE)

# Display top correlations
print(cor_nmr_sorted)


# reomve the variable of births attended by skilled health personnel as it is highly correlated
nfhs5 <- nfhs5 %>% select(-Births.attended.by.skilled.health.personnel.in.the.5.years.before.the.survey10.Pct)


colnames(nfhs5)

#  boxplots
par(mfrow=c(1,1)) # Reset plot layout
boxplot(nfhs5$Neonatal.mortality.rate.per.1000.live.births, main="Boxplot of Neonatal Mortality Rate", horizontal=TRUE)

# find outliers using IQR method

# Identify numeric columns
numeric_cols <- sapply(nfhs5, is.numeric)

# Apply IQR method to find outliers
outliers <- apply(nfhs5[, numeric_cols], 2, function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR_value <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR_value
  upper_bound <- Q3 + 1.5 * IQR_value
  
  # Return the values that are outliers
  x[x < lower_bound | x > upper_bound]
})

# Show variables with outliers
outliers <- outliers[sapply(outliers, length) > 0]  # Remove empty lists

# Print variables that have outliers
names(outliers)

# since we are doing Random Forest first, we will include all the variables

# Load necessary libraries
# Load necessary libraries
library(randomForest)
library(caret)  # For train-test split
set.seed(123)

# Define independent (X) and dependent (Y) variables
X <- nfhs5 %>% select(-Neonatal.mortality.rate.per.1000.live.births)  # Exclude target
Y <- nfhs5$Neonatal.mortality.rate.per.1000.live.births

# Split dataset (80% train, 20% test)
train_index <- createDataPartition(Y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
Y_train <- Y[train_index]
X_test <- X[-train_index, ]
Y_test <- Y[-train_index]

#there are missing values.

colSums(is.na(X_train)) / nrow(X_train) * 100  # Check % of missing data per column


# as there are small missing values, less than 10%, we will impute


# Impute missing values using median
preprocess <- preProcess(X_train, method = "medianImpute")
X_train <- predict(preprocess, X_train)
X_test <- predict(preprocess, X_test)  # Apply the same transformation to test data

# Calculate optimal mtry
mtry_value <- floor(ncol(X_train) / 3)

# Train Random Forest
rf_model <- randomForest(X_train, Y_train, ntree = 500, mtry = mtry_value, importance = TRUE)


# Print OOB error summary
print(rf_model)

# Plot OOB error over trees
plot(rf_model, main = "Random Forest OOB Error Rate")

# the OOB error plot suggests the the trees of 200-300 are enough. We have to tune the model again


# ✅ Step 2: Optimize Random Forest Parameters
mtry_value <- floor(sqrt(ncol(X_train)))  # Use square root rule for mtry
ntree_value <- 300  # Based on OOB error analysis

# ✅ Step 3: Train Optimized Random Forest Model
rf_model_tuned <- randomForest(X_train, Y_train, ntree = ntree_value, mtry = mtry_value, importance = TRUE)

# Print new model summary
print(rf_model_tuned)

# Plot OOB error
plot(rf_model_tuned, main = "Random Forest OOB Error After Optimization")

# OK, this model performed better than the previous one. Now we will select the top 10 variables and do another Random Forest modelling

# Extract the top 10 variables

# Extract feature importance from the tuned Random Forest model
importance_table <- as.data.frame(importance(rf_model_tuned))
importance_table <- importance_table[order(-importance_table$IncNodePurity), ]  # Sort by importance

# Select top 10 most important variables
top_10_vars <- rownames(importance_table)[1:10]
print(top_10_vars)

#There is StatesUTs. We will remove that will include the next important variable to make it to top 10 variables.

# Remove 'StatesUTs' from the top 10 list
top_10_vars <- top_10_vars[top_10_vars != "StatesUTs"]

# If we now have only 9 variables, add the next most important one
if (length(top_10_vars) < 10) {
  next_best_var <- rownames(importance_table)[11]  # Get the 11th most important variable
  top_10_vars <- c(top_10_vars, next_best_var)  # Add it to the list
}

# Print updated top 10 variables
print(top_10_vars)


# Subset data with top 10 features
X_train_top10 <- X_train[, top_10_vars]
X_test_top10 <- X_test[, top_10_vars]

# Train new RF model with only 10 features
rf_model_top10 <- randomForest(X_train_top10, Y_train, ntree = 300, mtry = floor(sqrt(length(top_10_vars))), importance = TRUE)

# Print new model summary
print(rf_model_top10)

# Predict on test set
predictions_top10 <- predict(rf_model_top10, X_test_top10)

# Compute RMSE
test_rmse_top10 <- sqrt(mean((Y_test - predictions_top10)^2))
print(paste("Test RMSE after feature selection:", round(test_rmse_top10, 2)))

# Now that RMSE is calculated, let us proceed with MLR

# Train MLR model using only top 10 variables
mlr_model <- lm(Y_train ~ ., data = as.data.frame(cbind(Y_train, X_train_top10)))

# View MLR summary
summary(mlr_model)

par(mfrow = c(2,2))  # Multiple plots
plot(mlr_model)


# since just 2 variables are significant in the MLR model, we will do another MLR with just these two variables

# Select only the significant variables
X_train_significant <- X_train_top10[, c("Total.Fertility.Rate.number.of.children.per.woman",
                                         "Current.Use.of.Family.Planning.Methods.Currently.Married.Women.Age.15.49..years...Condom.Pct")]

# Retrain the MLR model with only significant variables
mlr_model_refined <- lm(Y_train ~ ., data = as.data.frame(cbind(Y_train, X_train_significant)))

# View refined MLR summary
summary(mlr_model_refined)

# Lets compare MLR and RF with RMSE and MAE

# Predict on test data
mlr_predictions <- predict(mlr_model_refined, X_test_top10)
rf_predictions <- predict(rf_model_top10, X_test_top10)

# Compute RMSE
mlr_rmse <- sqrt(mean((Y_test - mlr_predictions)^2))
rf_rmse <- sqrt(mean((Y_test - rf_predictions)^2))

# Compute MAE
mlr_mae <- mean(abs(Y_test - mlr_predictions))
rf_mae <- mean(abs(Y_test - rf_predictions))

# Print results
print(paste("MLR Test RMSE:", round(mlr_rmse, 2)))
print(paste("RF Test RMSE:", round(rf_rmse, 2)))
print(paste("MLR Test MAE:", round(mlr_mae, 2)))
print(paste("RF Test MAE:", round(rf_mae, 2)))

#Feature Importance: the most influential factors affecting Neonatal Mortality Rate (NMR)

# Plot feature importance
varImpPlot(rf_model_top10, main = "Top Features Influencing Neonatal Mortality Rate")

# Load ggplot2
library(ggplot2)

# Extract feature importance from RF model
rf_importance <- as.data.frame(importance(rf_model_top10))
rf_importance$Feature <- rownames(rf_importance)  # Add column for feature names

# Select top 10 most important variables
rf_importance <- rf_importance[order(-rf_importance$IncNodePurity), ][1:10, ]

# Create bar plot
ggplot(rf_importance, aes(x = reorder(Feature, IncNodePurity), y = IncNodePurity)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +  # Flip coordinates for better readability
  labs(title = "Top 10 Features Influencing Neonatal Mortality Rate",
       x = "Feature",
       y = "Importance (IncNodePurity)") +
  theme_minimal()










 
```







